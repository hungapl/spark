{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(title,StringType,true),StructField(author,StringType,true),StructField(type,StringType,true),StructField(price,IntegerType,true)))\n",
      "+-------------------+------------+--------+-----+\n",
      "|              title|      author|    type|price|\n",
      "+-------------------+------------+--------+-----+\n",
      "|       Where's Spot|   Eric Hill|Children|   10|\n",
      "| The Cat In The Hat|   Dr. Seuss|Children|   15|\n",
      "|Jamie's 15 Min Meal|Jamie Oliver|Adult NF|   20|\n",
      "+-------------------+------------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Based on Spark 2.3.0 Doc https://spark.apache.org/docs/latest/rdd-programming-guide.html\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "data = spark.read.csv(\"books.csv\", header=True, inferSchema=True)\n",
    "print(data.schema)\n",
    "data.show()\n",
    "\n",
    "books = data.rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Map**\n",
    "- apply a function to each element and return an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[\"Where's Spot by Eric Hill\", 'The Cat In The Hat by Dr. Seuss', \"Jamie's 15 Min Meal by Jamie Oliver\"]\n"
     ]
    }
   ],
   "source": [
    "results = books.map(lambda b: b.title + \" by \" + b.author).collect()\n",
    "print(type(results))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FlatMap**\n",
    "- return a collection of the iterables returned by the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[\"Where's\", 'Spot', 'The', 'Cat', 'In', 'The', 'Hat', \"Jamie's\", '15', 'Min', 'Meal']\n"
     ]
    }
   ],
   "source": [
    "results = books.flatMap(lambda b: b.title.split(' ')).collect()\n",
    "print(type(results))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter**\n",
    "- return elements that satisify the specified condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reduce**\n",
    "- Reduces the elements of this RDD using the specified commutative and associative binary operator.  \n",
    "- Returns the same type of RDD as the input RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import add\n",
    "spark.sparkContext.parallelize([1, 2, 3, 4, 5]).reduce(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[Row(title='The Cat In The Hat', author='Dr. Seuss', type='Children', price=15), Row(title=\"Jamie's 15 Min Meal\", author='Jamie Oliver', type='Adult NF', price=20)]\n"
     ]
    }
   ],
   "source": [
    "results = books.filter(lambda b: b.price > 12).collect()\n",
    "print(type(results))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aggregate**\n",
    "Aggregates the elements of each partition, and then the results for all the partitions, using a given combine functions and a neutral “zero value.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqOp = (lambda x, y: (x[0] + y, x[1] + 1))\n",
    "combOp = (lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "sc.parallelize([1, 2, 3, 4]).aggregate((0, 0), seqOp, combOp)\n",
    "(10, 4)\n",
    ">>> sc.parallelize([]).aggregate((0, 0), seqOp, combOp)\n",
    "(0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Persistence**\n",
    "-  When you persist an RDD, each node stores any partitions of it that it computes in memory and reuses them in other actions on that dataset (or datasets derived from it). This allows future actions to be much faster (often by more than 10x)\n",
    "- *cache()* is a shorthand for using the default storage level. which is StorageLevel.MEMORY_ONLY.  Other storage level includes:MEMORY_AND_DISK, DISK_ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(title='The Cat In The Hat', author='Dr. Seuss', type='Children', price=15), Row(title=\"Jamie's 15 Min Meal\", author='Jamie Oliver', type='Adult NF', price=20)]\n",
      "[Row(title='The Cat In The Hat', author='Dr. Seuss', type='Children', price=15), Row(title=\"Jamie's 15 Min Meal\", author='Jamie Oliver', type='Adult NF', price=20)]\n",
      "[Row(title='The Cat In The Hat', author='Dr. Seuss', type='Children', price=15), Row(title=\"Jamie's 15 Min Meal\", author='Jamie Oliver', type='Adult NF', price=20)]\n",
      "[Row(title='The Cat In The Hat', author='Dr. Seuss', type='Children', price=15), Row(title=\"Jamie's 15 Min Meal\", author='Jamie Oliver', type='Adult NF', price=20)]\n",
      "[Row(title='The Cat In The Hat', author='Dr. Seuss', type='Children', price=15), Row(title=\"Jamie's 15 Min Meal\", author='Jamie Oliver', type='Adult NF', price=20)]\n",
      "[Row(title='The Cat In The Hat', author='Dr. Seuss', type='Children', price=15), Row(title=\"Jamie's 15 Min Meal\", author='Jamie Oliver', type='Adult NF', price=20)]\n",
      "[Row(title='The Cat In The Hat', author='Dr. Seuss', type='Children', price=15), Row(title=\"Jamie's 15 Min Meal\", author='Jamie Oliver', type='Adult NF', price=20)]\n",
      "[Row(title='The Cat In The Hat', author='Dr. Seuss', type='Children', price=15), Row(title=\"Jamie's 15 Min Meal\", author='Jamie Oliver', type='Adult NF', price=20)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    print(books.filter(lambda b: b.price > 12).collect())\n",
    "\n",
    "# Versus #\n",
    "\n",
    "cached = books.filter(lambda b: b.price > 12).cache()\n",
    "for i in range(1, 5):\n",
    "    print(cached.collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
