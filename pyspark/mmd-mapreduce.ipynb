{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: Stanford University - Mining Massive Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map and Reduce\n",
    "` Map(k, v) -> <k', v'>`\n",
    "<p>Input to **map** is a set of key-value (kv) pairs and this method should produce zero or more intermediate kv pairs that is the number of intermediate kv pairs is not necessarily to the number input kv pairs. </p>\n",
    "\n",
    "`Reduce(k', <v'>*) -> <k', v''>*`\n",
    "<p>The **reduce** function takes an intermediate kv pairs *group*.  A kv pairs group consists of a key and a set of values for that key</p>\n",
    "\n",
    "#### Example\n",
    "Word counting example\n",
    "Map - reads input and produces a set of kv pairs where the key is the word and the value is the number 1\n",
    "Group by Key - collect all pairs with same key\n",
    "Reduce - collect all values belonging to the key and output\n",
    "**Distributed computation**\n",
    "- File is separated into chunks and replicates in multiple nodes\n",
    "- Each node examine a different chunk\n",
    "- The system copies the output of the map function into a single node, such that the pairs can be forwarded to reduce node.\n",
    "- The system can be using multiple reduce node and to ensure pairs with the key goes to the same reduce node, the system uses a hash function on the key to determine which reduce node to ship the data to.\n",
    "- Once the data reaches the reduce node, the data is sorted and collected together (reduce)\n",
    "\n",
    "**Map-Reduce environment takes care of:**\n",
    "- *Partitioning* the data\n",
    "- *Scheduling* the program's execution across a set of machines\n",
    "- *Performing* the group by key step\n",
    "- Handling node *failures*\n",
    "- Manage all inter-machine communications\n",
    "\n",
    "### Data Flow\n",
    "- Input and final output are stored on the *distributed file system (DFS)*: Tries to schedule map tasks close to physical location of input data.  \n",
    "- Intermediate results are stored on local FS of Map-Reduce workers as storing in the distributed is expensive to copy and shuffle data in the network\n",
    "### Master node\n",
    "- Take care of coordination\n",
    "- When a map task completes, it sends the master the location and sizes of its R intermediate files, one for each reducer\n",
    "- Master pushes this info to reducers\n",
    "- Master pings workers periodically to detect failures\n",
    "\n",
    "### Map worker failure\n",
    "- When a worker fails, all the completed and in-progress tasks at workers are reset to idle\n",
    "- Idle tasks are eventually rescheduled on other workers\n",
    "### Reduce worker failure\n",
    "- As completed tasks immediately send output to master, so only in-progress tasks are rest to idle\n",
    "### Master failure\n",
    "- MapReduce task is aborted and client is notified.  Entire task needs to be restarted\n",
    "\n",
    "\n",
    "### Number of Map and Reduce jobs?\n",
    "- M map tasks, R reduce tasks\n",
    "- Usually M is larger than the number of nodes in the cluster, ideally one map task per data chunk.  More efficient\n",
    "- R is smaller than the number of nodes because it is more convenient to have output spread across a smaller number of nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
